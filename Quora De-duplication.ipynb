{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all the required library in once place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U keras\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install spacy\n",
    "# !pip install pandas\n",
    "# !pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import BatchNormalization, Dense, Input\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global helper functions\n",
    "\n",
    "These helper functions will be used throughout for stuff like pickling/unpickling data at each checkpoints, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_exists(namespace, name):\n",
    "    dirname = os.path.join('data', namespace)\n",
    "    filename = os.path.join(dirname, name + '.pickle')\n",
    "\n",
    "    return os.path.exists(filename)\n",
    "\n",
    "\n",
    "def save_data(namespace, name, content):\n",
    "    dirname = os.path.join('data', namespace)\n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "\n",
    "    filename = os.path.join(dirname, name + '.pickle')\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(content, f)\n",
    "\n",
    "\n",
    "def load_data(namespace, name):\n",
    "    dirname = os.path.join('data', namespace)\n",
    "    filename = os.path.join(dirname, name + '.pickle')\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Quora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'train.csv'\n",
    "data = pd.read_csv(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 404290\n",
      "Total positive entries: 149263\n",
      "Total negative entries: 255027\n",
      "Percent positive entries: 36.9197853026\n",
      "Percent negative entries: 63.0802146974\n"
     ]
    }
   ],
   "source": [
    "# Total number of entries\n",
    "ad_total_entries = len(data)\n",
    "print(\"Total entries: {}\".format(ad_total_entries))\n",
    "\n",
    "# Types of entries\n",
    "ad_positive_entries = len(data[data['is_duplicate'] == 1])\n",
    "print(\"Total positive entries: {}\".format(ad_positive_entries))\n",
    "\n",
    "ad_negative_entries = len(data[data['is_duplicate'] == 0])\n",
    "print(\"Total negative entries: {}\".format(ad_negative_entries))\n",
    "\n",
    "ad_percent_pos = 100.0 * ad_positive_entries / ad_total_entries\n",
    "print(\"Percent positive entries: {}\".format(ad_percent_pos))\n",
    "\n",
    "ad_percent_neg = 100.0 * ad_negative_entries / ad_total_entries\n",
    "print(\"Percent negative entries: {}\".format(ad_percent_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>Method to find separation of slits using fresn...</td>\n",
       "      <td>What are some of the things technicians can te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>How can I see all my Youtube comments?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>What can make Physics easy to learn?</td>\n",
       "      <td>How can you make physics easy to learn?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>What was your first sexual experience like?</td>\n",
       "      <td>What was your first sexual experience?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>What are the laws to change your status from a...</td>\n",
       "      <td>What are the laws to change your status from a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>What would a Trump presidency mean for current...</td>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>What does manipulation mean?</td>\n",
       "      <td>What does manipulation means?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>Why do girls want to be friends with the guy t...</td>\n",
       "      <td>How do guys feel after rejecting a girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>Why are so many Quora users posting questions ...</td>\n",
       "      <td>Why do people ask Quora questions which can be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>Which is the best digital marketing institutio...</td>\n",
       "      <td>Which is the best digital marketing institute ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  qid1  qid2                                          question1  \\\n",
       "0    0     1     2  What is the step by step guide to invest in sh...   \n",
       "1    1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2    2     5     6  How can I increase the speed of my internet co...   \n",
       "3    3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4    4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5    5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6    6    13    14                                Should I buy tiago?   \n",
       "7    7    15    16                     How can I be a good geologist?   \n",
       "8    8    17    18                    When do you use シ instead of し?   \n",
       "9    9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "10  10    21    22  Method to find separation of slits using fresn...   \n",
       "11  11    23    24        How do I read and find my YouTube comments?   \n",
       "12  12    25    26               What can make Physics easy to learn?   \n",
       "13  13    27    28        What was your first sexual experience like?   \n",
       "14  14    29    30  What are the laws to change your status from a...   \n",
       "15  15    31    32  What would a Trump presidency mean for current...   \n",
       "16  16    33    34                       What does manipulation mean?   \n",
       "17  17    35    36  Why do girls want to be friends with the guy t...   \n",
       "18  18    37    38  Why are so many Quora users posting questions ...   \n",
       "19  19    39    40  Which is the best digital marketing institutio...   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "0   What is the step by step guide to invest in sh...             0  \n",
       "1   What would happen if the Indian government sto...             0  \n",
       "2   How can Internet speed be increased by hacking...             0  \n",
       "3   Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4             Which fish would survive in salt water?             0  \n",
       "5   I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6   What keeps childern active and far from phone ...             0  \n",
       "7           What should I do to be a great geologist?             1  \n",
       "8               When do you use \"&\" instead of \"and\"?             0  \n",
       "9   How do I hack Motorola DCX3400 for free internet?             0  \n",
       "10  What are some of the things technicians can te...             0  \n",
       "11             How can I see all my Youtube comments?             1  \n",
       "12            How can you make physics easy to learn?             1  \n",
       "13             What was your first sexual experience?             1  \n",
       "14  What are the laws to change your status from a...             0  \n",
       "15  How will a Trump presidency affect the student...             1  \n",
       "16                      What does manipulation means?             1  \n",
       "17           How do guys feel after rejecting a girl?             0  \n",
       "18  Why do people ask Quora questions which can be...             1  \n",
       "19  Which is the best digital marketing institute ...             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse sample questions\n",
    "data.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "We can extract features in several different ways, and we goota try them all too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get GloVe vectors for each word\n",
    "def get_vectors_for_text(nlp, text):\n",
    "    return np.array([w.vector for w in nlp(text)])\n",
    "\n",
    "# Take the mean of all the rows, thus getting a single\n",
    "# row in the end\n",
    "def mean_pool(text_vectors):\n",
    "    return np.mean(text_vectors, axis=0)\n",
    "\n",
    "# Take the max from all rows, thus getting a single\n",
    "# row in the end\n",
    "def max_pool(text_vectors):\n",
    "    return np.max(text_vectors, axis=0)\n",
    "\n",
    "# Concat of max and mean pool of all vectors\n",
    "def features_for_text(nlp, text):\n",
    "    vectors = get_vectors_for_text(nlp, text)\n",
    "    \n",
    "    return np.concatenate((max_pool(vectors), mean_pool(vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.038548  ,  0.54251999, -0.21843   , ...,  0.11798   ,\n",
       "         0.24590001,  0.22872999],\n",
       "       [-0.084961  ,  0.50199997,  0.0023823 , ..., -0.21511   ,\n",
       "        -0.26304001, -0.0060173 ],\n",
       "       [ 0.27204001, -0.06203   , -0.1884    , ...,  0.13015001,\n",
       "        -0.18317001,  0.1323    ],\n",
       "       ..., \n",
       "       [ 0.089187  ,  0.25792   ,  0.26282001, ...,  0.14421   ,\n",
       "        -0.169     ,  0.26501   ],\n",
       "       [-0.89548999,  0.38773   ,  0.64984   , ...,  0.1375    ,\n",
       "        -0.26706001,  0.57568997],\n",
       "       [-0.086864  ,  0.19160999,  0.10915   , ..., -0.01516   ,\n",
       "         0.11108   ,  0.20649999]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vectors_for_text(nlp, unicode(data.loc[0]['question1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_vectors(nlp, data):\n",
    "    if data_exists('features', 'vectors'):\n",
    "        return load_data('features', 'vectors')\n",
    "    \n",
    "    features = {\n",
    "        'question1': [],\n",
    "        'question2': [],\n",
    "        'is_duplicate': []\n",
    "    }\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        try:\n",
    "            row = data.loc[i]\n",
    "            q1 = features_for_text(nlp, unicode(row['question1']))\n",
    "            q2 = features_for_text(nlp, unicode(row['question2']))\n",
    "\n",
    "            features['question1'].append(q1)\n",
    "            features['question2'].append(q2)\n",
    "            features['is_duplicate'].append(row['is_duplicate'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    features['question1'] = np.asarray(features['question1'])\n",
    "    features['question2'] = np.asarray(features['question2'])\n",
    "    features['is_duplicate'] = np.asarray(features['is_duplicate'])\n",
    "    \n",
    "    save_data('features', 'vectors', features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25233001  0.10176    -0.67484999  0.21117     0.43492001  0.16542\n",
      "  0.48260999 -0.81221998  0.041321    0.78501999 -0.077857   -0.66324002\n",
      "  0.1464     -0.29289001 -0.25488001  0.019293   -0.20265     0.98232001\n",
      "  0.028312   -0.081276   -0.1214      0.13125999 -0.17648     0.13556001\n",
      " -0.16361    -0.22574     0.055006   -0.20308     0.20717999  0.095785\n",
      "  0.22481     0.21537    -0.32982001 -0.12241    -0.40031001 -0.079381\n",
      " -0.19958    -0.015083   -0.079139   -0.18132     0.20681    -0.36195999\n",
      " -0.30744001 -0.24422    -0.23113     0.09798     0.1463     -0.062738\n",
      "  0.42934    -0.078038   -0.19627     0.65092999 -0.22807001 -0.30307999\n",
      " -0.12483    -0.17568    -0.14651     0.15361001 -0.29517999  0.15098999\n",
      " -0.51726002 -0.033564   -0.23108999 -0.78329998  0.018029   -0.15719\n",
      "  0.02293     0.49639001  0.029225    0.05669     0.14616001 -0.19194999\n",
      "  0.16244     0.23898     0.36431     0.45263001  0.2456      0.23803\n",
      "  0.31399     0.34869999 -0.035791    0.56107998 -0.25345001  0.051964\n",
      " -0.10618    -0.30961999  1.05850005 -0.42025     0.18216    -0.11256\n",
      "  0.40575999  0.11784    -0.19705001 -0.075292    0.080723   -0.02782\n",
      " -0.15617    -0.44681001 -0.15165     0.1692      0.098255   -0.031894\n",
      "  0.087143    0.26082     0.002706    0.1319      0.34439    -0.37893999\n",
      " -0.41139999  0.081571   -0.11674    -0.43711001  0.011144    0.099353\n",
      "  0.26611999  0.40024999  0.18895    -0.18437999 -0.30355    -0.27250001\n",
      "  0.22468001 -0.40614     0.15617999 -0.16043     0.47147     0.0080203\n",
      "  0.56857997  0.21934    -0.11181     0.79925001  0.10714    -0.50146002\n",
      "  0.063593    0.069465    0.15291999 -0.27469999 -0.20988999  0.20737\n",
      " -0.10681     0.40651    -2.64380002 -0.31139001 -0.32157001 -0.26458001\n",
      " -0.35624999  0.070013   -0.18838     0.48773    -0.26166999 -0.020805\n",
      "  0.17818999  0.15758    -0.13752     0.056464    0.30766001 -0.066136\n",
      "  0.47479999 -0.27335     0.09732    -0.20832001  0.0039332   0.34599999\n",
      " -0.08702    -0.54923999 -0.18759    -0.17174     0.060324   -0.13521001\n",
      "  0.10419     0.30164999  0.05798     0.21872    -0.073594   -0.20423\n",
      " -0.25279    -0.10471    -0.32163     0.12525    -0.31281     0.0097207\n",
      " -0.26776999 -0.61120999 -0.11089    -0.13652     0.035135   -0.4939\n",
      "  0.084857   -0.15493999 -0.063509   -0.23935001  0.28272     0.10849\n",
      " -0.33649999 -0.60764003  0.38576001 -0.0095438   0.17499    -0.52723002\n",
      "  0.62211001  0.19543999 -0.48977     0.036582   -0.12800001 -0.016827\n",
      "  0.25646999 -0.31698     0.48256999 -0.14184     0.11046    -0.3098\n",
      " -0.63141    -0.37268001  0.23183    -0.14268    -0.02341     0.022255\n",
      " -0.044662   -0.16404    -0.25848001  0.1629      0.024751    0.23348001\n",
      "  0.27932999  0.38997999 -0.058968    0.11355     0.15673     0.18583\n",
      " -0.19814    -0.48122999 -0.035084    0.078458   -0.49833     0.10855\n",
      " -0.20133001  0.05292    -0.11583    -0.16009     0.16768     0.42361999\n",
      " -0.23106     0.082465    0.24296001 -0.16786     0.0080409   0.085947\n",
      "  0.38033     0.072981    0.16329999  0.24704    -0.11094     0.15115\n",
      " -0.22068    -0.061944   -0.037091   -0.087923   -0.23181     0.15035\n",
      " -0.19092999 -0.19113    -0.11894     0.094908   -0.0043347   0.15362\n",
      " -0.41201001 -0.3073      0.18375     0.40206    -0.0034793  -0.10917\n",
      " -0.69521999  0.10161    -0.079256    0.40329     0.22284999 -0.19374\n",
      " -0.13315     0.073231    0.099832    0.11685    -0.21642999 -0.1108\n",
      "  0.10341     0.097286    0.11196    -0.38940001 -0.0089363   0.28808999\n",
      " -0.10792     0.028811    0.32545     0.26052001 -0.038941    0.075204\n",
      "  0.46031001 -0.06293     0.21661     0.17869    -0.51916999  0.33590999]\n"
     ]
    }
   ],
   "source": [
    "print(nlp(u'hello').vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all vectors to a file to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = save_vectors(nlp, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "\n",
    "I'm gonna be trying multiple networks with different hyper-parameters. I'm keen on knowing what kind of improvement each component can contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'no_weights': 100, 'batch_norm': True, 'no_layers': 2}, {'no_weights': 100, 'batch_norm': True, 'no_layers': 4}, {'no_weights': 100, 'batch_norm': True, 'no_layers': 6}, {'no_weights': 100, 'batch_norm': True, 'no_layers': 8}, {'no_weights': 100, 'batch_norm': False, 'no_layers': 2}, {'no_weights': 100, 'batch_norm': False, 'no_layers': 4}, {'no_weights': 100, 'batch_norm': False, 'no_layers': 6}, {'no_weights': 100, 'batch_norm': False, 'no_layers': 8}, {'no_weights': 200, 'batch_norm': True, 'no_layers': 2}, {'no_weights': 200, 'batch_norm': True, 'no_layers': 4}, {'no_weights': 200, 'batch_norm': True, 'no_layers': 6}, {'no_weights': 200, 'batch_norm': True, 'no_layers': 8}, {'no_weights': 200, 'batch_norm': False, 'no_layers': 2}, {'no_weights': 200, 'batch_norm': False, 'no_layers': 4}, {'no_weights': 200, 'batch_norm': False, 'no_layers': 6}, {'no_weights': 200, 'batch_norm': False, 'no_layers': 8}, {'no_weights': 300, 'batch_norm': True, 'no_layers': 2}, {'no_weights': 300, 'batch_norm': True, 'no_layers': 4}, {'no_weights': 300, 'batch_norm': True, 'no_layers': 6}, {'no_weights': 300, 'batch_norm': True, 'no_layers': 8}, {'no_weights': 300, 'batch_norm': False, 'no_layers': 2}, {'no_weights': 300, 'batch_norm': False, 'no_layers': 4}, {'no_weights': 300, 'batch_norm': False, 'no_layers': 6}, {'no_weights': 300, 'batch_norm': False, 'no_layers': 8}]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Define all combinations\n",
    "model_params = {\n",
    "    # Should we use batch normalization or not?\n",
    "    'batch_norm': [True, False],\n",
    "    \n",
    "    # No. of weights in each layer. All layers will have the same\n",
    "    # weights with ReLU activation\n",
    "    'no_weights': [100, 200, 300],\n",
    "    \n",
    "    # No. of layers\n",
    "    'no_layers': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "def generate_combinations(params):\n",
    "    keys = params.keys()\n",
    "    \n",
    "    # Generate combinations of current key\n",
    "    current_key = keys[0]\n",
    "    current_combinations = []\n",
    "    for value in params[current_key]:\n",
    "        d = {}\n",
    "        d[current_key] = value\n",
    "        current_combinations.append(d)\n",
    "        \n",
    "    # Check if we need recursive processing\n",
    "    if len(keys) > 1:\n",
    "        other_combinations = generate_combinations({k:v for k,v in params.iteritems() if k != current_key})\n",
    "        all_combinations = []\n",
    "        \n",
    "        for i in current_combinations:\n",
    "            for j in other_combinations:\n",
    "                all_combinations.append(dict(i.items() + j.items()))\n",
    "                \n",
    "        return all_combinations\n",
    "    else:\n",
    "        return current_combinations\n",
    "    \n",
    "all_combinations = generate_combinations(model_params)\n",
    "print(all_combinations)\n",
    "print(len(all_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    input_1 = Input(shape=(600,), name='question1')\n",
    "    input_2 = Input(shape=(600,), name='question2')\n",
    "    layer = keras.layers.concatenate([input_1, input_2])\n",
    "    \n",
    "    for i in range(params['no_layers']):\n",
    "        if params['batch_norm']:\n",
    "            layer = BatchNormalization()(layer)\n",
    "        \n",
    "        layer = Dense(params['no_weights'], activation='relu')(layer)\n",
    "        \n",
    "    output = Dense(1, activation='sigmoid')(layer)\n",
    "    \n",
    "    model = Model(inputs=[input_1, input_2], outputs=[output])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355993\n",
      "395548\n"
     ]
    }
   ],
   "source": [
    "TEST_SPLIT = 0.9\n",
    "TEST_INDEX = int(TEST_SPLIT * len(vectors['question1']))\n",
    "\n",
    "print(TEST_INDEX)\n",
    "print(len(vectors['question1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_name_from_params(params):\n",
    "    return \"{}_{}_{}.h5\".format(str(params['no_weights']), str(params['batch_norm']), str(params['no_layers']))\n",
    "\n",
    "def train_model(features, params):\n",
    "    model = get_model(params)\n",
    "    name = get_name_from_params(params)\n",
    "    \n",
    "    if os.path.exists(name):\n",
    "        print(\"Already exists: {}\".format(name))\n",
    "        return load_model(name)\n",
    "    else:\n",
    "        print(\"Processing: {}\".format(name))\n",
    "    \n",
    "    callbacks = [ModelCheckpoint(name, monitor='val_acc', save_best_only=True), CSVLogger(name + '.log')]\n",
    "    \n",
    "    question1 = features['question1'][0:TEST_INDEX,]\n",
    "    question2 = features['question2'][0:TEST_INDEX,]\n",
    "    is_duplicate = features['is_duplicate'][0:TEST_INDEX,]\n",
    "    \n",
    "    model.fit([question1, question2], is_duplicate, epochs=25, validation_split=0.1,\n",
    "              verbose=True, callbacks=callbacks)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: 100_True_2.h5\n",
      "Already exists: 100_True_4.h5\n",
      "Already exists: 100_True_6.h5\n",
      "Already exists: 100_True_8.h5\n",
      "Already exists: 100_False_2.h5\n",
      "Already exists: 100_False_4.h5\n",
      "Already exists: 100_False_6.h5\n",
      "Already exists: 100_False_8.h5\n",
      "Already exists: 200_True_2.h5\n",
      "Already exists: 200_True_4.h5\n",
      "Already exists: 200_True_6.h5\n",
      "Already exists: 200_True_8.h5\n",
      "Already exists: 200_False_2.h5\n",
      "Already exists: 200_False_4.h5\n",
      "Already exists: 200_False_6.h5\n",
      "Already exists: 200_False_8.h5\n",
      "Already exists: 300_True_2.h5\n",
      "Already exists: 300_True_4.h5\n",
      "Already exists: 300_True_6.h5\n",
      "Already exists: 300_True_8.h5\n",
      "Already exists: 300_False_2.h5\n",
      "Already exists: 300_False_4.h5\n",
      "Processing: 300_False_6.h5\n",
      "Train on 320393 samples, validate on 35600 samples\n",
      "Epoch 1/25\n",
      "320393/320393 [==============================] - 667s - loss: 0.5520 - acc: 0.7134 - val_loss: 0.5384 - val_acc: 0.7309\n",
      "Epoch 2/25\n",
      "320393/320393 [==============================] - 785s - loss: 0.5106 - acc: 0.7424 - val_loss: 0.4989 - val_acc: 0.7460\n",
      "Epoch 3/25\n",
      "320393/320393 [==============================] - 802s - loss: 0.4945 - acc: 0.7520 - val_loss: 0.5085 - val_acc: 0.7470\n",
      "Epoch 4/25\n",
      "320393/320393 [==============================] - 810s - loss: 0.4840 - acc: 0.7587 - val_loss: 0.4821 - val_acc: 0.7595\n",
      "Epoch 5/25\n",
      "320393/320393 [==============================] - 820s - loss: 0.4769 - acc: 0.7635 - val_loss: 0.4927 - val_acc: 0.7481\n",
      "Epoch 6/25\n",
      "320393/320393 [==============================] - 845s - loss: 0.4715 - acc: 0.7668 - val_loss: 0.4742 - val_acc: 0.7627\n",
      "Epoch 7/25\n",
      "320393/320393 [==============================] - 985s - loss: 0.4666 - acc: 0.7699 - val_loss: 0.4806 - val_acc: 0.7632\n",
      "Epoch 8/25\n",
      "320393/320393 [==============================] - 1255s - loss: 0.4624 - acc: 0.7723 - val_loss: 0.4705 - val_acc: 0.7658\n",
      "Epoch 9/25\n",
      "320393/320393 [==============================] - 1384s - loss: 0.4604 - acc: 0.7734 - val_loss: 0.4822 - val_acc: 0.7617\n",
      "Epoch 10/25\n",
      "320393/320393 [==============================] - 1405s - loss: 0.4564 - acc: 0.7759 - val_loss: 0.4672 - val_acc: 0.7695\n",
      "Epoch 11/25\n",
      "320393/320393 [==============================] - 1425s - loss: 0.4538 - acc: 0.7769 - val_loss: 0.4594 - val_acc: 0.7730\n",
      "Epoch 12/25\n",
      "320393/320393 [==============================] - 1454s - loss: 0.4513 - acc: 0.7793 - val_loss: 0.4913 - val_acc: 0.7610\n",
      "Epoch 13/25\n",
      "320393/320393 [==============================] - 1459s - loss: 0.4488 - acc: 0.7807 - val_loss: 0.4594 - val_acc: 0.7725\n",
      "Epoch 14/25\n",
      "320393/320393 [==============================] - 1423s - loss: 0.4465 - acc: 0.7826 - val_loss: 0.4777 - val_acc: 0.7613\n",
      "Epoch 15/25\n",
      "320393/320393 [==============================] - 1424s - loss: 0.4452 - acc: 0.7835 - val_loss: 0.4603 - val_acc: 0.7714\n",
      "Epoch 16/25\n",
      "320393/320393 [==============================] - 1423s - loss: 0.4428 - acc: 0.7843 - val_loss: 0.4637 - val_acc: 0.7702\n",
      "Epoch 17/25\n",
      "320393/320393 [==============================] - 1458s - loss: 0.4409 - acc: 0.7859 - val_loss: 0.4553 - val_acc: 0.7768\n",
      "Epoch 18/25\n",
      "320393/320393 [==============================] - 1473s - loss: 0.4392 - acc: 0.7864 - val_loss: 0.4537 - val_acc: 0.7752\n",
      "Epoch 19/25\n",
      "320393/320393 [==============================] - 1478s - loss: 0.4374 - acc: 0.7879 - val_loss: 0.4537 - val_acc: 0.7747\n",
      "Epoch 20/25\n",
      "320393/320393 [==============================] - 1518s - loss: 0.4361 - acc: 0.7884 - val_loss: 0.4526 - val_acc: 0.7754\n",
      "Epoch 21/25\n",
      "320393/320393 [==============================] - 1482s - loss: 0.4343 - acc: 0.7895 - val_loss: 0.4606 - val_acc: 0.7745\n",
      "Epoch 22/25\n",
      "320393/320393 [==============================] - 1500s - loss: 0.4336 - acc: 0.7896 - val_loss: 0.4633 - val_acc: 0.7709\n",
      "Epoch 23/25\n",
      "320393/320393 [==============================] - 1482s - loss: 0.4315 - acc: 0.7917 - val_loss: 0.4528 - val_acc: 0.7765\n",
      "Epoch 24/25\n",
      "320393/320393 [==============================] - 1474s - loss: 0.4299 - acc: 0.7922 - val_loss: 0.4551 - val_acc: 0.7754\n",
      "Epoch 25/25\n",
      "320393/320393 [==============================] - 1488s - loss: 0.4286 - acc: 0.7932 - val_loss: 0.4591 - val_acc: 0.7730\n",
      "Already exists: 300_False_8.h5\n"
     ]
    }
   ],
   "source": [
    "for combination in all_combinations:\n",
    "    train_model(vectors, combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
